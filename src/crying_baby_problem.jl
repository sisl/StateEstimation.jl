### A Pluto.jl notebook ###
# v0.12.4

using Markdown
using InteractiveUtils

# â•”â•â•¡ 634b2ed0-0f1a-11eb-30aa-e1092f5f338f
md"""
# Crying Baby Problem
For code, see [StateEstimation.jl](https://github.com/mossr/StateEstimation.jl)

We cannot directly observe whether the baby is hungry or not (i.e. the true states), but we can observe if it is *crying* or *quite* and use that as a noisy observation to update our beliefs about their true state.
"""

# â•”â•â•¡ 7b68d4d0-0f20-11eb-2484-b354c4cff750
md"""
The state, action, and observation spaces are:

$$\begin{align}
	\mathcal{S} &= \{\text{hungry},\, \text{sated}\}\tag{state space}\\
	\mathcal{A} &= \{\text{feed},\, \text{sing},\, \text{ignore}\}\tag{action space}\\
	\mathcal{O} &= \{\text{crying},\, \text{quiet}\}\tag{observation space}
\end{align}$$
"""

# â•”â•â•¡ 70bb6df0-0f1a-11eb-0055-25079b36caaf
begin
	@enum State hungry sated
	@enum Action feed sing ignore
	@enum Observation crying quiet
end

# â•”â•â•¡ a0d7ddc0-0f1a-11eb-291d-59e2b1633f67
md"""
## POMDP definition
"""

# â•”â•â•¡ 105acfb0-195a-11eb-0920-89dfeeedd245
md"""
$$\langle \mathcal{S}, \mathcal{A}, \mathcal{O}, T, R, O, \gamma \rangle\tag{POMDP 7-tuple}$$
"""

# â•”â•â•¡ a4f86280-0f1a-11eb-104e-8fef3d3303ef
struct POMDP
	ğ’® # state space
	ğ’œ # action space
	ğ’ª # observation space
	T # transition function
	R # reward function
	O # observation function
	Î³ # discount factor
end

# â•”â•â•¡ 7b94ae80-0f1a-11eb-1aef-eb26390584d8
md"""
## Transition model
Also called the *transition function*.
"""

# â•”â•â•¡ 928b39a0-0f20-11eb-10e9-d1289faf91f9
md"""
$$T(s^\prime \mid a, s)$$

$$\begin{aligned}
    T(\text{sated}  \ \mid &\>\text{hungry}, \text{feed}) &= 100\% \\
    T(\text{hungry} \ \mid &\>\text{hungry}, \text{sing}) &= 100\% \\
    T(\text{hungry} \ \mid &\>\text{hungry}, \text{ignore}) &= 100\% \\
    T(\text{sated}  \ \mid &\>\text{sated}, \text{feed}) &= 100\% \\
    T(\text{hungry} \ \mid &\>\text{sated}, \text{sing}) &= 10\% \\
    T(\text{hungry} \ \mid &\>\text{sated}, \text{ignore}) &= 10\%
\end{aligned}$$
"""

# â•”â•â•¡ 7569dace-0f1a-11eb-3530-ab7c4a4b0163
function T(s, a, sâ€²)
	if a == feed
		return sâ€² == hungry ? 0 : 1
	elseif s == hungry && (a == sing || a == ignore)
		return sâ€² == hungry ? 1 : 0
	elseif s == sated && (a == sing || a == ignore)
		return sâ€² == hungry ? 0.1 : 0.9
	end
end

# â•”â•â•¡ 80c2f9c0-0f1a-11eb-1cd4-a128ecee865d
md"""
## Reward model
Also called the *reward function*. We assign $-10$ reward if the baby is hungry and $-5$ reward for feeding the baby (which is additive). Singing to a *sated* baby yields $5$ reward, but singing to a *hungry* baby incurs $-2$ reward.

$$R(s,a)$$
"""

# â•”â•â•¡ 77b50350-0f1a-11eb-3518-2f84ee105ca1
function R(s, a)
	return (s == hungry ? -10 : 0) +
	       (a == feed ? -5 : 0) +
	       (a == sing && s == sated ? +5 : 0) +
	       (a == sing && s == hungry ? -2 : 0)
end

# â•”â•â•¡ 8a9c0860-0f1a-11eb-312f-cf748280d3e6
md"""
## Observation model
A *hungry* baby cries $80\%$ of the time, whereas a *sated* baby cries $10\%$ of the time. Singing to the baby yields a perfect observation.

$$O(o \mid a, s^\prime)$$
"""

# â•”â•â•¡ 7a273bd0-0f1a-11eb-3218-8b33c0141bb8
function O(a, sâ€², o)
	if a == sing # perfect observation
		if sâ€² == hungry
			return o == crying ? 1 : 0
		elseif sâ€² == sated
			return o == crying ? 0 : 1
		end
	elseif sâ€² == hungry
		o == crying ? 0.8 : 0.2
	elseif sâ€² == sated
		o == crying ? 0.1 : 0.9
	end
end

# â•”â•â•¡ b22f1b10-0f1a-11eb-229e-ed202606a72c
md"""
## Belief updating
$$\begin{gather}
b^\prime(s^\prime) \propto O(o \mid a, s^\prime) \sum_s T(s^\prime \mid s, a)b(s) \tag{then normalize}
\end{gather}$$
"""

# â•”â•â•¡ b04ebe20-0f21-11eb-2607-0b01c99ac423
import LinearAlgebra: normalize!

# â•”â•â•¡ b4db7662-0f1a-11eb-3fb8-d58feae7e66c
function update(b::Vector{Float64}, ğ’«, a, o)
	ğ’®, T, O = ğ’«.ğ’® ,ğ’«.T, ğ’«.O
	bâ€² = similar(b)
	for (iâ€², sâ€²) in enumerate(ğ’®)
		bâ€²[iâ€²] = O(a, sâ€², o) * sum(T(s, a, sâ€²) * b[i] for (i, s) in enumerate(ğ’®))
	end
	if sum(bâ€²) â‰ˆ 0.0
		fill!(bâ€², 1)
	end
	return normalize!(bâ€², 1)
end

# â•”â•â•¡ 84db99ce-0f1b-11eb-27a3-678c1c091540
md"""
# Instantiating the crying baby POMDP
"""

# â•”â•â•¡ e35cb6de-1959-11eb-09dc-938c74a5877b
# State, action, and observation spaces (or sets)
begin
	ğ’® = (hungry, sated)
	ğ’œ = (feed, sing, ignore)
	ğ’ª = (crying, quiet)
end;

# â•”â•â•¡ 90dba720-0f1b-11eb-2d19-f501bb8f3286
ğ’« = POMDP(ğ’®,   # state space
	      ğ’œ,   # action space
	      ğ’ª,   # observation space
	      T,   # transition model
	      R,   # reward model
	      O,   # observation model
		  0.9) # discount factor

# â•”â•â•¡ b1dc4ab0-0f1b-11eb-3f29-dbfcbd991121
md"""
## Example: updaing beliefs
$$\mathbf b = \begin{bmatrix} p(\text{hungry}) \\ p(\text{sated})\end{bmatrix} = \text{belief vector over states}$$
"""

# â•”â•â•¡ bcbda190-0f1b-11eb-147e-79986a90edef
md"""
We start with an initial uniform belief $b_0$ across the states *hungry* and *sated*.
"""

# â•”â•â•¡ b9fa62e0-0f1b-11eb-0bbd-271d46693d2b
bâ‚€ = [0.5, 0.5]

# â•”â•â•¡ cde25d30-0f1b-11eb-2fa3-65e902a27818
md"""
Then we update our belief if we *ignore* the baby and observe it *crying*.
"""

# â•”â•â•¡ dc904c70-0f1b-11eb-0a8c-bd9770a4a074
bâ‚ = update(bâ‚€, ğ’«, ignore, crying)

# â•”â•â•¡ dd5a5330-0f1b-11eb-3fe5-6f3ae2246b2a
md"""
Updating again after we *feed* the baby and observe it becomes *quiet*.
"""

# â•”â•â•¡ 03157190-0f1c-11eb-3658-493ade3025d2
bâ‚‚ = update(bâ‚, ğ’«, feed, quiet)

# â•”â•â•¡ 752b1230-0f1c-11eb-1d64-5314eabbd247
md"""
Then we *ignore* the baby and still observe it is *quiet*.
"""

# â•”â•â•¡ 81dfa26e-0f1c-11eb-3753-4713abb1b5cc
bâ‚ƒ = update(bâ‚‚, ğ’«, ignore, quiet)

# â•”â•â•¡ a1ee6bf0-0f1c-11eb-25fb-9b2508e6ceed
md"""
Again we *ignore* the baby and still observe it is *quiet*.
"""

# â•”â•â•¡ 9625c250-0f1c-11eb-11fd-0d7c8cef3ad2
bâ‚„ = update(bâ‚ƒ, ğ’«, ignore, quiet)

# â•”â•â•¡ 869477f0-0f1c-11eb-1a0c-5d59b8c2145d
md"""
Finally, we *ignore* the baby again and observe that it's *crying*.
"""

# â•”â•â•¡ a8b817b0-0f1c-11eb-055b-a34848891544
bâ‚… = update(bâ‚„, ğ’«, ignore, crying)

# â•”â•â•¡ ac8dfee0-0f1c-11eb-0207-ed93b0d6f9fc
md"""
And recall, this final belief $b_5$ is telling us that we *believe* the baby is **hungry** with probability $0.538$ and that it is **sated** with probability $0.462$. Only given observations and without seeing the true state.
"""

# â•”â•â•¡ Cell order:
# â•Ÿâ”€634b2ed0-0f1a-11eb-30aa-e1092f5f338f
# â•Ÿâ”€7b68d4d0-0f20-11eb-2484-b354c4cff750
# â• â•70bb6df0-0f1a-11eb-0055-25079b36caaf
# â•Ÿâ”€a0d7ddc0-0f1a-11eb-291d-59e2b1633f67
# â•Ÿâ”€105acfb0-195a-11eb-0920-89dfeeedd245
# â• â•a4f86280-0f1a-11eb-104e-8fef3d3303ef
# â•Ÿâ”€7b94ae80-0f1a-11eb-1aef-eb26390584d8
# â•Ÿâ”€928b39a0-0f20-11eb-10e9-d1289faf91f9
# â• â•7569dace-0f1a-11eb-3530-ab7c4a4b0163
# â•Ÿâ”€80c2f9c0-0f1a-11eb-1cd4-a128ecee865d
# â• â•77b50350-0f1a-11eb-3518-2f84ee105ca1
# â•Ÿâ”€8a9c0860-0f1a-11eb-312f-cf748280d3e6
# â• â•7a273bd0-0f1a-11eb-3218-8b33c0141bb8
# â•Ÿâ”€b22f1b10-0f1a-11eb-229e-ed202606a72c
# â• â•b04ebe20-0f21-11eb-2607-0b01c99ac423
# â• â•b4db7662-0f1a-11eb-3fb8-d58feae7e66c
# â•Ÿâ”€84db99ce-0f1b-11eb-27a3-678c1c091540
# â• â•e35cb6de-1959-11eb-09dc-938c74a5877b
# â• â•90dba720-0f1b-11eb-2d19-f501bb8f3286
# â•Ÿâ”€b1dc4ab0-0f1b-11eb-3f29-dbfcbd991121
# â•Ÿâ”€bcbda190-0f1b-11eb-147e-79986a90edef
# â• â•b9fa62e0-0f1b-11eb-0bbd-271d46693d2b
# â•Ÿâ”€cde25d30-0f1b-11eb-2fa3-65e902a27818
# â• â•dc904c70-0f1b-11eb-0a8c-bd9770a4a074
# â•Ÿâ”€dd5a5330-0f1b-11eb-3fe5-6f3ae2246b2a
# â• â•03157190-0f1c-11eb-3658-493ade3025d2
# â•Ÿâ”€752b1230-0f1c-11eb-1d64-5314eabbd247
# â• â•81dfa26e-0f1c-11eb-3753-4713abb1b5cc
# â•Ÿâ”€a1ee6bf0-0f1c-11eb-25fb-9b2508e6ceed
# â• â•9625c250-0f1c-11eb-11fd-0d7c8cef3ad2
# â•Ÿâ”€869477f0-0f1c-11eb-1a0c-5d59b8c2145d
# â• â•a8b817b0-0f1c-11eb-055b-a34848891544
# â•Ÿâ”€ac8dfee0-0f1c-11eb-0207-ed93b0d6f9fc
